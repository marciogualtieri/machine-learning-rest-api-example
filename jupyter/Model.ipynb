{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Example REST API with Machine Using Flask and Scikit-learn\n",
    "\n",
    "by Marcio Gualtieri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing Dependencies\n",
    "\n",
    "Run this block of code to install all these dependencies if you don't have them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already up-to-date: pip in /home/franco/.local/lib/python3.8/site-packages (20.2.3)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas==1.1.2 in /home/franco/.local/lib/python3.8/site-packages (1.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/lib/python3/dist-packages (from pandas==1.1.2) (2.7.3)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /home/franco/.local/lib/python3.8/site-packages (from pandas==1.1.2) (1.19.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/franco/.local/lib/python3.8/site-packages (from pandas==1.1.2) (2020.1)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn==0.23.2 in /home/franco/.local/lib/python3.8/site-packages (0.23.2)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/franco/.local/lib/python3.8/site-packages (from scikit-learn==0.23.2) (1.19.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/franco/.local/lib/python3.8/site-packages (from scikit-learn==0.23.2) (0.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/franco/.local/lib/python3.8/site-packages (from scikit-learn==0.23.2) (2.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /home/franco/.local/lib/python3.8/site-packages (from scikit-learn==0.23.2) (1.5.2)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: matplotlib==3.3.1 in /home/franco/.local/lib/python3.8/site-packages (3.3.1)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in /home/franco/.local/lib/python3.8/site-packages (from matplotlib==3.3.1) (2020.6.20)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/franco/.local/lib/python3.8/site-packages (from matplotlib==3.3.1) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/franco/.local/lib/python3.8/site-packages (from matplotlib==3.3.1) (0.10.0)\n",
      "Requirement already satisfied: numpy>=1.15 in /home/franco/.local/lib/python3.8/site-packages (from matplotlib==3.3.1) (1.19.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /home/franco/.local/lib/python3.8/site-packages (from matplotlib==3.3.1) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/lib/python3/dist-packages (from matplotlib==3.3.1) (2.7.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/lib/python3/dist-packages (from matplotlib==3.3.1) (7.0.0)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from cycler>=0.10->matplotlib==3.3.1) (1.14.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: Flask==1.1.2 in /home/franco/.local/lib/python3.8/site-packages (1.1.2)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in /home/franco/.local/lib/python3.8/site-packages (from Flask==1.1.2) (1.1.0)\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in /usr/lib/python3/dist-packages (from Flask==1.1.2) (2.10.1)\n",
      "Requirement already satisfied: Werkzeug>=0.15 in /home/franco/.local/lib/python3.8/site-packages (from Flask==1.1.2) (1.0.1)\n",
      "Requirement already satisfied: click>=5.1 in /home/franco/.local/lib/python3.8/site-packages (from Flask==1.1.2) (7.1.2)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install --upgrade pip\n",
    "!{sys.executable} -m pip install pandas==1.1.2\n",
    "!{sys.executable} -m pip install scikit-learn==0.23.2\n",
    "!{sys.executable} -m pip install matplotlib==3.3.1\n",
    "!{sys.executable} -m pip install Flask==1.1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Dependencies\n",
    "\n",
    "All the imports go here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from flask import Flask, jsonify, request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Synthetic Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be defining a global seed for the whole notebook for reproducibility:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 123\n",
    "\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For computing a dataframe with synthetic random data, we are going to define the following functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_numbers(N):\n",
    "    return np.random.randn(1, N)[0]\n",
    "\n",
    "assert generate_numbers(3).shape == (3,)\n",
    "assert generate_numbers(3).dtype == np.dtype('float64')\n",
    "\n",
    "def generate_letters(N):\n",
    "    return np.random.choice(list(string.ascii_uppercase), N)\n",
    "\n",
    "assert generate_letters(3).shape == (3,)\n",
    "assert generate_letters(3).dtype == np.dtype('<U1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that this is just an example, we are going to use a fairly small data-set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NUMBER1</th>\n",
       "      <th>NUMBER2</th>\n",
       "      <th>NUMBER3</th>\n",
       "      <th>LETTER1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>-0.662023</td>\n",
       "      <td>0.053536</td>\n",
       "      <td>-1.129567</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>0.182635</td>\n",
       "      <td>0.065770</td>\n",
       "      <td>0.166094</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>-0.345676</td>\n",
       "      <td>-0.046507</td>\n",
       "      <td>-1.450647</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>0.195246</td>\n",
       "      <td>0.311453</td>\n",
       "      <td>-0.103934</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>0.540774</td>\n",
       "      <td>-0.204227</td>\n",
       "      <td>0.682255</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>-1.590748</td>\n",
       "      <td>0.335376</td>\n",
       "      <td>-0.298454</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>-0.309896</td>\n",
       "      <td>-0.256017</td>\n",
       "      <td>1.611584</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>0.118998</td>\n",
       "      <td>-1.012662</td>\n",
       "      <td>0.120498</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>1.637441</td>\n",
       "      <td>0.062215</td>\n",
       "      <td>-0.368085</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>-0.524849</td>\n",
       "      <td>1.295082</td>\n",
       "      <td>-0.206787</td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.236347</td>\n",
       "      <td>-0.353372</td>\n",
       "      <td>1.606744</td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>-0.362114</td>\n",
       "      <td>-1.335804</td>\n",
       "      <td>-1.793359</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      NUMBER1   NUMBER2   NUMBER3 LETTER1\n",
       "863 -0.662023  0.053536 -1.129567       A\n",
       "432  0.182635  0.065770  0.166094       G\n",
       "643 -0.345676 -0.046507 -1.450647       P\n",
       "944  0.195246  0.311453 -0.103934       I\n",
       "325  0.540774 -0.204227  0.682255       G\n",
       "782 -1.590748  0.335376 -0.298454       G\n",
       "462 -0.309896 -0.256017  1.611584       Z\n",
       "920  0.118998 -1.012662  0.120498       C\n",
       "570  1.637441  0.062215 -0.368085       R\n",
       "115 -0.524849  1.295082 -0.206787       J\n",
       "8    0.236347 -0.353372  1.606744       J\n",
       "928 -0.362114 -1.335804 -1.793359       N"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 1000\n",
    "\n",
    "data_df = pd.DataFrame(columns=['NUMBER1', 'NUMBER2', 'NUMBER3', 'LETTER1'])\n",
    "data_df.NUMBER1 = generate_numbers(N)\n",
    "data_df.NUMBER2 = generate_numbers(N)\n",
    "data_df.NUMBER3 = generate_numbers(N)\n",
    "data_df.LETTER1 = generate_letters(N)\n",
    "\n",
    "data_df.sample(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The specification for this challenge refered to \"numbers\", which usually means float numbers, not integers, thus, we are dealing with continous variables, which implies regression for any of the numeric columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to apply one-hot encoding for the only categorical feature, that is, \"LETTER1\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NUMBER1</th>\n",
       "      <th>NUMBER2</th>\n",
       "      <th>NUMBER3</th>\n",
       "      <th>LETTER1_A</th>\n",
       "      <th>LETTER1_B</th>\n",
       "      <th>LETTER1_C</th>\n",
       "      <th>LETTER1_D</th>\n",
       "      <th>LETTER1_E</th>\n",
       "      <th>LETTER1_F</th>\n",
       "      <th>LETTER1_G</th>\n",
       "      <th>...</th>\n",
       "      <th>LETTER1_Q</th>\n",
       "      <th>LETTER1_R</th>\n",
       "      <th>LETTER1_S</th>\n",
       "      <th>LETTER1_T</th>\n",
       "      <th>LETTER1_U</th>\n",
       "      <th>LETTER1_V</th>\n",
       "      <th>LETTER1_W</th>\n",
       "      <th>LETTER1_X</th>\n",
       "      <th>LETTER1_Y</th>\n",
       "      <th>LETTER1_Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>0.971047</td>\n",
       "      <td>-0.736352</td>\n",
       "      <td>-1.034197</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>-0.974754</td>\n",
       "      <td>0.363989</td>\n",
       "      <td>0.768231</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>-1.485573</td>\n",
       "      <td>-0.357539</td>\n",
       "      <td>-0.714663</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>0.069857</td>\n",
       "      <td>0.995418</td>\n",
       "      <td>1.246920</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>1.003126</td>\n",
       "      <td>1.828910</td>\n",
       "      <td>-1.404956</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>-0.097375</td>\n",
       "      <td>1.387062</td>\n",
       "      <td>1.254441</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>-0.280841</td>\n",
       "      <td>-0.993701</td>\n",
       "      <td>2.775053</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>0.184864</td>\n",
       "      <td>-0.383106</td>\n",
       "      <td>0.159136</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>-0.271584</td>\n",
       "      <td>0.487785</td>\n",
       "      <td>-0.655541</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>-0.992187</td>\n",
       "      <td>-1.355146</td>\n",
       "      <td>-0.943882</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>-0.342863</td>\n",
       "      <td>0.885068</td>\n",
       "      <td>-1.078344</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784</th>\n",
       "      <td>0.785589</td>\n",
       "      <td>-0.468208</td>\n",
       "      <td>1.409434</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      NUMBER1   NUMBER2   NUMBER3  LETTER1_A  LETTER1_B  LETTER1_C  LETTER1_D  \\\n",
       "127  0.971047 -0.736352 -1.034197          0          0          0          0   \n",
       "375 -0.974754  0.363989  0.768231          0          0          0          0   \n",
       "545 -1.485573 -0.357539 -0.714663          0          0          0          0   \n",
       "636  0.069857  0.995418  1.246920          0          0          0          0   \n",
       "905  1.003126  1.828910 -1.404956          0          0          0          0   \n",
       "224 -0.097375  1.387062  1.254441          0          1          0          0   \n",
       "781 -0.280841 -0.993701  2.775053          0          0          0          0   \n",
       "208  0.184864 -0.383106  0.159136          0          0          0          0   \n",
       "458 -0.271584  0.487785 -0.655541          0          0          0          0   \n",
       "799 -0.992187 -1.355146 -0.943882          0          0          0          0   \n",
       "695 -0.342863  0.885068 -1.078344          0          0          0          0   \n",
       "784  0.785589 -0.468208  1.409434          0          0          0          0   \n",
       "\n",
       "     LETTER1_E  LETTER1_F  LETTER1_G  ...  LETTER1_Q  LETTER1_R  LETTER1_S  \\\n",
       "127          0          0          0  ...          1          0          0   \n",
       "375          0          0          0  ...          0          1          0   \n",
       "545          0          0          0  ...          0          0          0   \n",
       "636          0          0          0  ...          0          0          0   \n",
       "905          0          0          0  ...          0          0          0   \n",
       "224          0          0          0  ...          0          0          0   \n",
       "781          0          0          0  ...          0          0          0   \n",
       "208          0          0          0  ...          1          0          0   \n",
       "458          0          0          0  ...          0          1          0   \n",
       "799          0          0          0  ...          0          0          0   \n",
       "695          0          0          0  ...          0          0          0   \n",
       "784          0          0          0  ...          0          0          0   \n",
       "\n",
       "     LETTER1_T  LETTER1_U  LETTER1_V  LETTER1_W  LETTER1_X  LETTER1_Y  \\\n",
       "127          0          0          0          0          0          0   \n",
       "375          0          0          0          0          0          0   \n",
       "545          0          0          0          0          1          0   \n",
       "636          0          0          0          0          1          0   \n",
       "905          0          0          0          0          0          1   \n",
       "224          0          0          0          0          0          0   \n",
       "781          0          0          0          0          0          0   \n",
       "208          0          0          0          0          0          0   \n",
       "458          0          0          0          0          0          0   \n",
       "799          0          0          1          0          0          0   \n",
       "695          0          0          0          0          0          1   \n",
       "784          0          0          0          0          0          0   \n",
       "\n",
       "     LETTER1_Z  \n",
       "127          0  \n",
       "375          0  \n",
       "545          0  \n",
       "636          0  \n",
       "905          0  \n",
       "224          0  \n",
       "781          0  \n",
       "208          0  \n",
       "458          0  \n",
       "799          0  \n",
       "695          0  \n",
       "784          0  \n",
       "\n",
       "[12 rows x 29 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df = pd.get_dummies(data_df)\n",
    "features_df.sample(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purposes of this experiment, we are going to use \"NUMBER1\" for the labels, thus, this immediately implies regression for our machine learning model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_name = 'NUMBER1'\n",
    "labels = np.array(features_df[label_name])\n",
    "\n",
    "features = features_df.drop(label_name, axis = 1)\n",
    "feature_names = list(features.columns)\n",
    "features = np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 28)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the one-hot encoding, we have 28 features (2 numeric and 26 categorical):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NUMBER2',\n",
       " 'NUMBER3',\n",
       " 'LETTER1_A',\n",
       " 'LETTER1_B',\n",
       " 'LETTER1_C',\n",
       " 'LETTER1_D',\n",
       " 'LETTER1_E',\n",
       " 'LETTER1_F',\n",
       " 'LETTER1_G',\n",
       " 'LETTER1_H',\n",
       " 'LETTER1_I',\n",
       " 'LETTER1_J',\n",
       " 'LETTER1_K',\n",
       " 'LETTER1_L',\n",
       " 'LETTER1_M',\n",
       " 'LETTER1_N',\n",
       " 'LETTER1_O',\n",
       " 'LETTER1_P',\n",
       " 'LETTER1_Q',\n",
       " 'LETTER1_R',\n",
       " 'LETTER1_S',\n",
       " 'LETTER1_T',\n",
       " 'LETTER1_U',\n",
       " 'LETTER1_V',\n",
       " 'LETTER1_W',\n",
       " 'LETTER1_X',\n",
       " 'LETTER1_Y',\n",
       " 'LETTER1_Z']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note again that this leaves us one label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NUMBER1'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step when trying to do feature engineering is to find the correlation between the labeland the features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NUMBER2      0.000973\n",
       "NUMBER3      0.038228\n",
       "LETTER1_A   -0.017539\n",
       "LETTER1_B   -0.034018\n",
       "LETTER1_C   -0.032077\n",
       "LETTER1_D    0.029479\n",
       "LETTER1_E   -0.019225\n",
       "LETTER1_F    0.028593\n",
       "LETTER1_G   -0.034286\n",
       "LETTER1_H    0.010499\n",
       "LETTER1_I   -0.003001\n",
       "LETTER1_J    0.025424\n",
       "LETTER1_K    0.028979\n",
       "LETTER1_L    0.008999\n",
       "LETTER1_M   -0.001687\n",
       "LETTER1_N   -0.017678\n",
       "LETTER1_O    0.010548\n",
       "LETTER1_P   -0.074807\n",
       "LETTER1_Q   -0.016054\n",
       "LETTER1_R    0.023006\n",
       "LETTER1_S    0.031968\n",
       "LETTER1_T   -0.041883\n",
       "LETTER1_U    0.088623\n",
       "LETTER1_V    0.020600\n",
       "LETTER1_W    0.005305\n",
       "LETTER1_X    0.000464\n",
       "LETTER1_Y   -0.052176\n",
       "LETTER1_Z    0.043355\n",
       "Name: NUMBER1, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df[features_df.columns].corr()[label_name][1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may have noticed that there isn't a significant correlation between the label and any of the features,\n",
    "which we can make it even more clear by using a visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [8, 8]\n",
    "plt.matshow(features_df.corr())\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In principle, only by looking at this diagram, we realize that there isn't much sense into using machine learning here, but given that the purpose of this notebook is to serve as an example of creating a regression model using [`sklearn`](https://scikit-learn.org/), let's keep going."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Base Model\n",
    "\n",
    "The purpose of this section is to create a base model with the default parameters that we can compare later with the best model that we can find.\n",
    "\n",
    "Our first step is to split our data-set into a training datas-set and a testing data-set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, test_features, train_labels, test_labels = train_test_split(\n",
    "    features,\n",
    "    labels,\n",
    "    test_size = 0.25,\n",
    "    random_state = SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We well be using 75% of our data-set for training and the remaining for evaluating our model.\n",
    "\n",
    "Let's create our base model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_random_forest_regressor = RandomForestRegressor(random_state = SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the hyperparamters for our base model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'criterion': 'mse',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': 123,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_random_forest_regressor.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that our label is a continuous variable, we will make use of a evaluation method proper for regression models, which could be root mean square error (RMSE), mean absolute error (MAE), R squared, or Adjusted R squared. We will be using the most popular one, RMSE, which happens to be part of the `sklearn` library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2882227094852712"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_random_forest_regressor.fit(train_features, train_labels);\n",
    "test_predictions = base_random_forest_regressor.predict(test_features)\n",
    "\n",
    "base_mean_squared_error = mean_squared_error(test_predictions, test_labels)\n",
    "base_mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Grid Search for the Best Model\n",
    "\n",
    "We need to find the hyperparameters that will give us the best fit. Here are the ranges we will be examining them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "\n",
    "max_features = ['auto', 'sqrt']\n",
    "\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "\n",
    "min_samples_split = [2, 5, 10]\n",
    "\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "bootstrap = [True, False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These ranges were obtained by trial and error. Given the values we get for best hyperparameters, it's safe to assume that they are within these ranges .\n",
    "\n",
    "Now we can build a configuration from these ranges:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000],\n",
       " 'max_features': ['auto', 'sqrt'],\n",
       " 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None],\n",
       " 'min_samples_split': [2, 5, 10],\n",
       " 'min_samples_leaf': [1, 2, 4],\n",
       " 'bootstrap': [True, False]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_grid_search_config = {\n",
    "    'n_estimators': n_estimators,\n",
    "    'max_features': max_features,\n",
    "    'max_depth': max_depth,\n",
    "    'min_samples_split': min_samples_split,\n",
    "    'min_samples_leaf': min_samples_leaf,\n",
    "    'bootstrap': bootstrap\n",
    "}\n",
    "\n",
    "random_grid_search_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we perform the grid search. This block of code will take the order of minutes to run, depending on your computer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   45.5s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  6.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=RandomForestRegressor(random_state=123),\n",
       "                   n_iter=100, n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110,\n",
       "                                                      None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]},\n",
       "                   random_state=123, verbose=2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_grid_search = RandomizedSearchCV(\n",
    "    estimator = base_random_forest_regressor,\n",
    "    param_distributions = random_grid_search_config,\n",
    "    n_iter = 100,\n",
    "    cv = 3,\n",
    "    verbose=2,\n",
    "    random_state=SEED,\n",
    "    n_jobs = -1)\n",
    "\n",
    "random_grid_search.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's the best hyperparameters found by the search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1200,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 4,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 10,\n",
       " 'bootstrap': True}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Best Model\n",
    "\n",
    "Now we can fit the model using our training data as we did for the base model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_random_forest_regressor = RandomForestRegressor(**random_grid_search.best_params_, random_state = SEED)\n",
    "best_random_forest_regressor.fit(train_features, train_labels);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again we are going to evaluate our best model using RMSE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1921136391585132"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions = best_random_forest_regressor.predict(test_features)\n",
    "\n",
    "best_mean_squared_error = mean_squared_error(test_predictions, test_labels)\n",
    "best_mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we have achieved quite a bit of reduction on the RMSE using random grid search.\n",
    "\n",
    "Usually, we would worry about the possibility of overfitting here, but given the nature of our data (synthetic, randomly generated, and with little correlation among them), we are going to stop analysis here. But we have proved the point that random grid search works.\n",
    "\n",
    "Now that we have our \"production model\". We are going to serialize it and save it to a file so we don't need to repeat the process of creating it all over again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = 'model.pickle'\n",
    "pickle.dump(best_random_forest_regressor, open(model_file, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use this model to build a predictive REST API in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Predictive REST API\n",
    "\n",
    "The plan is to send a POST request to our API with the following load:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"NUMBER2\": 2.,\n",
    "  \"NUMBER3\": 3.,\n",
    "  \"LETTER1\": \"A\"\n",
    "}\n",
    "```\n",
    "\n",
    "Which will return a prediction for \"NUMBER1\" as follows:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"NUMBER1\":[-0.040527403534144496]\n",
    "}\n",
    "```\n",
    "\n",
    "The first thing we need to do is to extract features from the input JSON data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode_feature(data, feature):\n",
    "     data[feature + '_' + data[feature]] = 1\n",
    "     del data[feature]\n",
    "     return data\n",
    "\n",
    "assert one_hot_encode_feature({'test_feature': 'A'}, 'test_feature') == {'test_feature_A': 1}\n",
    "    \n",
    "def extract_features(data):\n",
    "    one_hot_encode_feature(data, 'LETTER1')\n",
    "    data_df = pd.DataFrame(columns=feature_names)\n",
    "    data_df = data_df.append(data, ignore_index=True) \n",
    "    data_df = data_df.fillna(0)\n",
    "    return np.array(pd.get_dummies(data_df))\n",
    "\n",
    "np.testing.assert_array_equal(\n",
    "    extract_features(\n",
    "        {'NUMBER2': 2., 'NUMBER3': 3., 'LETTER1': 'A'}),\n",
    "        np.array([[2., 3., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "                   0., 0., 0., 0., 0., 0., 0., 0., 0.]]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can build a simple REST API using [`Flask`](https://flask.palletsprojects.com/en/1.1.x/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:8080/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [13/Sep/2020 17:37:25] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    }
   ],
   "source": [
    "app = Flask(__name__)\n",
    "\n",
    "model = pickle.load(open(model_file, 'rb' ) )\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "     prediction = model.predict(extract_features(request.json))\n",
    "     return jsonify({label_name: list(prediction)})\n",
    "\n",
    "app.run(port=8080)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above will run a Flask server in your localhost using port 8080. You need to stop the notebook's kernel to stop the server. While the server is running we my open a UNIX terminal and send a request using curl as follows:\n",
    "\n",
    "```bash\n",
    "curl --header \"Content-Type: application/json\" \\\n",
    "  --request POST \\\n",
    "  --data '{\"NUMBER2\": 2.0,\"NUMBER3\":3.0, \"LETTER1\": \"A\"}' \\\n",
    "  http://localhost:8080/predict\n",
    "```\n",
    "\n",
    "You should get a response similar to the following:\n",
    "\n",
    "```bash\n",
    "$ curl --header \"Content-Type: application/json\"   --request POST   --data '{\"NUMBER2\": 2.0,\"NUMBER3\":3.0, \"LETTER1\": \"A\"}'   http://localhost:8080/predict\n",
    "{\"NUMBER1\":[-0.040527403534144496]}\n",
    "```\n",
    "\n",
    "Normally (that is, in a production setting) I would separate the the REST API in its own project (with its own `requirements.txt`, unit tests, etc), but given that the purpose of this notebook is exploration, this should suffice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
